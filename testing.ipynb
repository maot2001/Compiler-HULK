{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from HULK_lexer_parser import HulkParser\n",
    "parser = HulkParser()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from HULK_lexer_parser import HulkLexer\n",
    "lexer = HulkLexer()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Expressions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "program = ''' 42; '''\n",
    "\n",
    "tokens = lexer(program)\n",
    "parse = parser([token.token_type for token in tokens])\n",
    "assert parse is not None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "program = '''print(42);'''\n",
    "\n",
    "tokens = lexer(program)\n",
    "parse = parser([token.token_type for token in tokens])\n",
    "assert parse is not None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "program = '''print((((1 + 2) ^ 3) * 4) / 5);'''\n",
    "\n",
    "tokens = lexer(program)\n",
    "parse = parser([token.token_type for token in tokens])\n",
    "assert parse is not None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "program = '''print(\"Hello World\");'''\n",
    "\n",
    "tokens = lexer(program)\n",
    "parse = parser([token.token_type for token in tokens])\n",
    "assert parse is not None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# program = '''print(\"The message is \\\"Hello World\\\"\");'''\n",
    "\n",
    "# tokens = lexer(program)\n",
    "# parse = parser([token.token_type for token in tokens])\n",
    "# assert parse is not None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "program = '''print(\"The meaning of life is \" @ 42);'''\n",
    "\n",
    "tokens = lexer(program)\n",
    "parse = parser([token.token_type for token in tokens])\n",
    "assert parse is not None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "program = '''print(sin(2 * PI) ^ 2 + cos(3 * PI / log(4, 64)));'''\n",
    "\n",
    "tokens = lexer(program)\n",
    "parse = parser([token.token_type for token in tokens])\n",
    "assert parse is not None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "program = '''{\n",
    "    print(42);\n",
    "    print(sin(PI/2));\n",
    "    print(\"Hello World\");\n",
    "}\n",
    "'''\n",
    "\n",
    "tokens = lexer(program)\n",
    "parse = parser([token.token_type for token in tokens])\n",
    "assert parse is not None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "program = '''function tan(x) => sin(x) / cos(x);'''\n",
    "\n",
    "tokens = lexer(program)\n",
    "parse = parser([token.token_type for token in tokens])\n",
    "assert parse is not None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[function: function, id: cot, (: (, id: x, ): ), =>: =>, num: 1, /: /, id: tan, (: (, id: x, ): ), ;: ;, function: function, id: tan, (: (, id: x, ): ), =>: =>, id: sin, (: (, id: x, ): ), /: /, id: cos, (: (, id: x, ): ), ;: ;, id: print, (: (, id: tan, (: (, id: PI, ): ), ^: ^, num: 2, +: +, id: cot, (: (, id: PI, ): ), ^: ^, num: 2, ): ), ;: ;, $: $]\n"
     ]
    }
   ],
   "source": [
    "program = ''' function cot(x) => 1 / tan(x);\n",
    "function tan(x) => sin(x) / cos(x);\n",
    "\n",
    "print(tan(PI) ^ 2 + cot(PI) ^ 2);\n",
    "'''\n",
    "\n",
    "tokens = lexer(program)\n",
    "print(tokens)\n",
    "parse = parser([token.token_type for token in tokens])\n",
    "assert parse is not None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "program = '''function operate(x, y) {\n",
    "    print(x + y);\n",
    "    print(x - y);\n",
    "    print(x * y);\n",
    "    print(x / y);\n",
    "}\n",
    "'''\n",
    "\n",
    "tokens = lexer(program)\n",
    "parse = parser([token.token_type for token in tokens])\n",
    "assert parse is not None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "program = '''let msg = \"Hello World\" in print(msg);\n",
    "'''\n",
    "\n",
    "tokens = lexer(program)\n",
    "parse = parser([token.token_type for token in tokens])\n",
    "assert parse is not None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "program = '''let number = 42, text = \"The meaning of life is\" in\n",
    "    print(text @ number);\n",
    "'''\n",
    "\n",
    "tokens = lexer(program)\n",
    "parse = parser([token.token_type for token in tokens])\n",
    "assert parse is not None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "program = '''let number = 42 in\n",
    "    let text = \"The meaning of life is\" in\n",
    "        print(text @ number);\n",
    " '''\n",
    "\n",
    "tokens = lexer(program)\n",
    "parse = parser([token.token_type for token in tokens])\n",
    "assert parse is not None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "program = '''let number = 42 in (\n",
    "    let text = \"The meaning of life is\" in (\n",
    "            print(text @ number)\n",
    "        )\n",
    "    );\n",
    " '''\n",
    "\n",
    "tokens = lexer(program)\n",
    "parse = parser([token.token_type for token in tokens])\n",
    "assert parse is not None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "program = ''' let a = 6, b = a * 7 in print(b);\n",
    "let a = 6 in\n",
    "    let b = a * 7 in\n",
    "        print(b);\n",
    "let a = 5, b = 10, c = 20 in {\n",
    "    print(a+b);\n",
    "    print(b*c);\n",
    "    print(c/a);\n",
    "}\n",
    "\n",
    "'''\n",
    "\n",
    "tokens = lexer(program)\n",
    "parse = parser([token.token_type for token in tokens])\n",
    "assert parse is not None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "program = ''' let a = (let b = 6 in b * 7) in print(a);\n",
    "print(let b = 6 in b * 7);\n",
    "let a = 20 in {\n",
    "    let a = 42 in print(a);\n",
    "    print(a);\n",
    "let a = 7, a = 7 * 6 in print(a);\n",
    "let a = 7 in\n",
    "    let a = 7 * 6 in\n",
    "        print(a);\n",
    "\n",
    "}\n",
    "\n",
    "'''\n",
    "\n",
    "tokens = lexer(program)\n",
    "parse = parser([token.token_type for token in tokens])\n",
    "assert parse is not None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "program = ''' let a = 0 in {\n",
    "    print(a);\n",
    "    a := 1;\n",
    "    print(a);\n",
    "}\n",
    "let a = 0 in\n",
    "    let b = a := 1 in {\n",
    "        print(a);\n",
    "        print(b);\n",
    "    };\n",
    "\n",
    "'''\n",
    "\n",
    "tokens = lexer(program)\n",
    "parse = parser([token.token_type for token in tokens])\n",
    "assert parse is not None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conditionals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "program = ''' let a = 42 in if (a % 2 == 0) print(\"Even\") else print(\"odd\");\n",
    "\n",
    "let a = 42 in print(if (a % 2 == 0) \"even\" else \"odd\");\n",
    "\n",
    "\n",
    "let a = 42 in\n",
    "    if (a % 2 == 0) {\n",
    "        print(a);\n",
    "        print(\"Even\");\n",
    "    }\n",
    "    else print(\"Odd\"); \n",
    "'''\n",
    "\n",
    "tokens = lexer(program)\n",
    "parse = parser([token.token_type for token in tokens])\n",
    "assert parse is not None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "program = '''let a = 42, mod = a % 3 in\n",
    "    print(\n",
    "        if (mod == 0) \"Magic\"\n",
    "        elif (mod % 3 == 1) \"Woke\"\n",
    "        else \"Dumb\"\n",
    "    );'''\n",
    "\n",
    "tokens = lexer(program)\n",
    "parse = parser([token.token_type for token in tokens])\n",
    "assert parse is not None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loops"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[let: let, id: a, =: =, num: 10, in: in, while: while, (: (, id: a, >=: >=, num: 0, ): ), {: {, id: print, (: (, id: a, ): ), ;: ;, id: a, :=: :=, id: a, -: -, num: 1, ;: ;, }: }, ;: ;, $: $]\n"
     ]
    }
   ],
   "source": [
    "program = ''' let a = 10 in while (a >= 0) {\n",
    "    print(a);\n",
    "    a := a - 1;\n",
    "};\n",
    "'''\n",
    "\n",
    "tokens = lexer(program)\n",
    "print(tokens)\n",
    "parse = parser([token.token_type for token in tokens])\n",
    "assert parse is not None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# program = ''' gcd ( a , b ) => while (a > 0)\n",
    "#     let m = hg in {\n",
    "#         b := a;\n",
    "#         a := m;\n",
    "#     } ;\n",
    "#  '''\n",
    "\n",
    "# tokens = lexer(program)\n",
    "# parse = parser([token.token_type for token in tokens])\n",
    "# assert parse is not None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "program = ''' for (x in range(0, 10)) print(x);\n",
    "let iterable = range(0, 10) in\n",
    "    while (iterable.next())\n",
    "        let x = iterable.current() in\n",
    "            print(x);\n",
    " '''\n",
    "\n",
    "tokens = lexer(program)\n",
    "parse = parser([token.token_type for token in tokens])\n",
    "assert parse is not None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# program = ''' type Point {\n",
    "#     x = 0;\n",
    "#     y = 0;\n",
    "\n",
    "#     getX() => self.x;\n",
    "#     getY() => self.y;\n",
    "\n",
    "#     setX(x) => self.x := x;\n",
    "#     setY(y) => self.y := y;\n",
    "# }\n",
    "\n",
    "# '''\n",
    "\n",
    "# tokens = lexer(program)\n",
    "# print(tokens)\n",
    "# parse = parser([token.token_type for token in tokens])\n",
    "# assert parse is not None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "program = '''let pt = new Point() in\n",
    "    print(\"x: \" @ pt.getX() @ \"; y: \" @ pt.getY());\n",
    "\n",
    "let pt = new Point(3,4) in\n",
    "    print(\"x: \" @ pt.getX() @ \"; y: \" @ pt.getY());\n",
    "\n",
    " '''\n",
    "\n",
    "tokens = lexer(program)\n",
    "parse = parser([token.token_type for token in tokens])\n",
    "assert parse is not None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[let: let, id: p, =: =, new: new, id: Knight, (: (, str: \"Phil\", ,: ,, str: \"Collins\", ): ), in: in, id: print, (: (, id: p, .: ., id: name, (: (, ): ), ): ), ;: ;, $: $]\n"
     ]
    }
   ],
   "source": [
    "program = ''' let p = new Knight(\"Phil\", \"Collins\") in\n",
    "    print(p.name());\n",
    "    \n",
    "'''\n",
    "\n",
    "tokens = lexer(program)\n",
    "print(tokens)\n",
    "parse = parser([token.token_type for token in tokens])\n",
    "assert parse is not None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Type checking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "program = ''' let x: Number = 42 in print(x);\n",
    "'''\n",
    "\n",
    "tokens = lexer(program)\n",
    "parse = parser([token.token_type for token in tokens])\n",
    "assert parse is not None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "program = ''' function tan(x: Number): Number => sin(x) / cos(x);\n",
    "\n",
    "let x = new Superman() in\n",
    "    print(\n",
    "        if (x is Bird) \"It's bird!\"\n",
    "        elif (x is Plane) \"It's a plane!\"\n",
    "        else \"No, it's Superman!\"\n",
    "    );\n",
    "\n",
    "\n",
    "'''\n",
    "\n",
    "tokens = lexer(program)\n",
    "parse = parser([token.token_type for token in tokens])\n",
    "assert parse is not None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "program = ''' let x : A = if (rand() < 0.5) new B() else new C() in\n",
    "    if (x is B)\n",
    "        let y : B = x as B in {\n",
    "            a;\n",
    "        }\n",
    "    else {\n",
    "        b;\n",
    "    };\n",
    "    '''\n",
    "\n",
    "tokens = lexer(program)\n",
    "parse = parser([token.token_type for token in tokens])\n",
    "assert parse is not None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Type inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "program = ''' function fib(n) => if (n == 0 | n == 1) 1 else fib(n-1) + fib(n-2);\n",
    "'''\n",
    "\n",
    "tokens = lexer(program)\n",
    "parse = parser([token.token_type for token in tokens])\n",
    "assert parse is not None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "program = '''function fact(x) => let f = 1 in for (i in range(1, x+1)) f := f * i;\n",
    " '''\n",
    "\n",
    "tokens = lexer(program)\n",
    "parse = parser([token.token_type for token in tokens])\n",
    "assert parse is not None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Protocols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "program = ''' protocol Hashable {\n",
    "    hash(): Number;\n",
    "}\n",
    "\n",
    "\n",
    "'''\n",
    "\n",
    "tokens = lexer(program)\n",
    "parse = parser([token.token_type for token in tokens])\n",
    "assert parse is not None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "program = ''' protocol Equatable extends Hashable {\n",
    "    equals(other: Object): Boolean;\n",
    "} \n",
    "\n",
    "let x : Hashable = new Person() in print(x.hash());\n",
    "'''\n",
    "\n",
    "tokens = lexer(program)\n",
    "parse = parser([token.token_type for token in tokens])\n",
    "assert parse is not None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Iterables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "program = '''\n",
    "protocol Iterable {\n",
    "    next() : Boolean;\n",
    "    current() : Object;\n",
    "} '''\n",
    "\n",
    "tokens = lexer(program)\n",
    "parse = parser([token.token_type for token in tokens])\n",
    "assert parse is not None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "program = ''' let iterable = range(0, 10) in\n",
    "    while (iterable.next())\n",
    "        let x = iterable.current() in {\n",
    "            print(x);\n",
    "        } ;\n",
    "'''\n",
    "\n",
    "parse = parser([token.token_type for token in tokens])\n",
    "assert parse is not None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "program = ''' let numbers = [1,2,3,4,5,6,7,8,9] in\n",
    "    for (x in numbers)\n",
    "        print(x);\n",
    "\n",
    "\n",
    "\n",
    "'''\n",
    "\n",
    "tokens = lexer(program)\n",
    "parse = parser([token.token_type for token in tokens])\n",
    "assert parse is not None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "program = ''' let numbers = [1,2,3,4,5,6,7,8,9] in print(numbers[7]);'''\n",
    "\n",
    "tokens = lexer(program)\n",
    "parse = parser([token.token_type for token in tokens])\n",
    "assert parse is not None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "program = ''' let squares = [x^2 || x in range(1,10)] in print(x);\n",
    "\n",
    "'''\n",
    "\n",
    "tokens = lexer(program)\n",
    "parse = parser([token.token_type for token in tokens])\n",
    "assert parse is not None"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
